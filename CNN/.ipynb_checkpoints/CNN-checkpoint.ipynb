{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9c5e011-34c9-4a63-b792-5ce5463035df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c60587cf-d669-434c-90ff-1c0db24d896f",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 'split1'\n",
    "path = \"../DATA/\"\n",
    "train_path = \"{}/{}/train/train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/{}/test/test_{}.csv\".format(path,split,split)\n",
    "valid_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f217691d-0a2e-4eea-a97a-92c673f59a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../DATA//split1/train/train_split1.csv\n",
      "../DATA//split1/test/test_split1.csv\n",
      "../DATA//split1/val/val_split1.csv\n"
     ]
    }
   ],
   "source": [
    "print(train_path)\n",
    "print(test_path)\n",
    "print(valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fc6bbc5-a2a9-4710-b111-3060fc759110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(292, 32)\n",
      "(292, 30)\n",
      "['B' 'M']\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "523d728a-c8a3-4746-88cf-c5523ff3fbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 32)\n",
      "(91, 30)\n",
      "['B' 'M']\n"
     ]
    }
   ],
   "source": [
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[2:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baa24d0c-8306-4987-9492-de684be31a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72, 32)\n",
      "(72, 30)\n",
      "['B' 'M']\n"
     ]
    }
   ],
   "source": [
    "# Load the validation set\n",
    "val_data = pd.read_csv(valid_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5464f9ab-f0d2-4bee-8e09-8c907e311a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "class WisconsinDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.X = x.values\n",
    "        self.y = y\n",
    "        self.X = torch.tensor(self.X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(self.y, dtype=torch.int64)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55a7f9f9-2f67-4ddf-a6f7-91987782ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, input_length):\n",
    "        super(CNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.conv1d_1 = nn.Conv1d(in_channels=embedding_dim, out_channels=5000, kernel_size=2)\n",
    "        self.max_pooling = nn.MaxPool1d(kernel_size=2)\n",
    "        self.conv1d_2 = nn.Conv1d(in_channels=5000, out_channels=1000, kernel_size=2)\n",
    "        self.avg_pooling = nn.AvgPool1d(kernel_size=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(torch.int64)  # Cast input tensor to torch.LongTensor\n",
    "        x = self.embedding(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.conv1d_1(x)\n",
    "        x = self.max_pooling(x)\n",
    "        x = self.conv1d_2(x)\n",
    "        x = self.avg_pooling(x)\n",
    "        x = self.flatten(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b8920d4-ef50-47e1-86c7-9842e0c93746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the datasets and data loaders\n",
    "val_dataset = WisconsinDataset(x_val, y_val)\n",
    "train_dataset = WisconsinDataset(x_train, y_train)\n",
    "test_dataset = WisconsinDataset(x_test, y_test)\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f558588-c7ce-4457-9594-c994ea76ec37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "num_features = len(le.classes_)\n",
    "print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5a0233b-8f10-4942-8e36-594beb5da71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292\n",
      "91\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader))\n",
    "print(len(test_loader))\n",
    "print(len(val_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "422bc6d8-6cc3-4136-847f-57c3d068bd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22538a4-f708-42b2-88cb-954f0e4eecc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a72d97b8-8bae-478a-a8ec-e87756eda0d0",
   "metadata": {},
   "source": [
    "## Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c52ec0e-6496-41b2-a2ad-ec8082cfe0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # extract a single instance from the dataset\n",
    "# data = next(iter(train_dataset))\n",
    "# print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8285efc-0f7b-477f-984e-8ac380b2373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert tensor to numpy array and flatten it\n",
    "# numpy_array = data[0].numpy().flatten()\n",
    "# print(numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8b33547-046d-4840-81e7-e15a332683a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a pandas DataFrame from the numpy array\n",
    "# df = pd.DataFrame(numpy_array)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3824f8ea-190c-4413-b5cb-9bf56625956f",
   "metadata": {},
   "source": [
    "### Data is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b869b67c-3c65-413c-aca7-eeeb42c95368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchinfo\n",
    "# !pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cef503c-3f19-4f1a-821c-94393903ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(vocab_size=20000, embedding_dim=300, input_length=31)\n",
    "inputs = torch.randint(low=0, high=20000, size=(1, 31))\n",
    "outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "091f395a-f0ee-4823-8f92-f5ca8f8845af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (embedding): Embedding(20000, 300, padding_idx=0)\n",
      "  (conv1d_1): Conv1d(300, 5000, kernel_size=(2,), stride=(1,))\n",
      "  (max_pooling): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv1d_2): Conv1d(5000, 1000, kernel_size=(2,), stride=(1,))\n",
      "  (avg_pooling): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c17b443-1f5a-47d2-a979-57520ca4edda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "CNN                                      --\n",
       "├─Embedding: 1-1                         6,000,000\n",
       "├─Conv1d: 1-2                            3,005,000\n",
       "├─MaxPool1d: 1-3                         --\n",
       "├─Conv1d: 1-4                            10,001,000\n",
       "├─AvgPool1d: 1-5                         --\n",
       "├─Flatten: 1-6                           --\n",
       "=================================================================\n",
       "Total params: 19,006,000\n",
       "Trainable params: 19,006,000\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "51c2f197-a216-48f1-afe5-b1ecfa548ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (embedding): Embedding(20000, 300, padding_idx=0)\n",
       "  (conv1d_1): Conv1d(300, 5000, kernel_size=(2,), stride=(1,))\n",
       "  (max_pooling): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv1d_2): Conv1d(5000, 1000, kernel_size=(2,), stride=(1,))\n",
       "  (avg_pooling): AvgPool1d(kernel_size=(2,), stride=(2,), padding=(0,))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1ff0d8c-6c45-4c22-9500-10e9255e4b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b732df2-a4c2-4b4a-8a8e-1b76102afd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b45ae69-8192-4fac-8ac7-61f5371a5a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "# criterion = nn.BCELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0fd75eba-8ee7-4c29-9fbb-76de5c90db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "learning_rate = 0.0001\n",
    "lr_step_size = 7\n",
    "lr_gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c993a3-bb25-4a6d-8ddc-0801518d319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train loss: 0.000, val loss: 10.146, val acc: 0.708\n",
      "Epoch 2, train loss: 0.000, val loss: 10.147, val acc: 0.708\n",
      "Epoch 3, train loss: 0.000, val loss: 10.148, val acc: 0.708\n",
      "Epoch 4, train loss: 0.000, val loss: 10.149, val acc: 0.708\n",
      "Epoch 5, train loss: 0.000, val loss: 10.150, val acc: 0.708\n",
      "Epoch 6, train loss: 0.000, val loss: 10.149, val acc: 0.708\n",
      "Epoch 7, train loss: 0.000, val loss: 10.149, val acc: 0.708\n",
      "Epoch 8, train loss: 0.000, val loss: 10.149, val acc: 0.708\n"
     ]
    }
   ],
   "source": [
    "# Move model and data to GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define optimizer and learning rate scheduler\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_step_size, gamma=lr_gamma)\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    # Set model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # Set model to eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        val_acc = 0.0\n",
    "        for i, data in enumerate(val_loader, 0):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_acc += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_acc /= len(val_loader.dataset)\n",
    "        \n",
    "    # Print progress\n",
    "    print('Epoch %d, train loss: %.3f, val loss: %.3f, val acc: %.3f' % \n",
    "          (epoch + 1, running_loss / len(train_loader), val_loss, val_acc))\n",
    "    \n",
    "    # Update learning rate scheduler\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1cbbd99d-4839-46d1-b950-c41956507e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "torch.save(model.state_dict(), 'breast-cancer-wisconsin-cnn.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ba38b7-048c-472a-9958-48d2e12204a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature maps for the input data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    feature_maps = model(input_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
