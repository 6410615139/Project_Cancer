{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9638b626-260c-486a-a872-4365f9b6910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "# from tqdm import tqdm\n",
    "# import time\n",
    "# import copy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# importing the statistics module\n",
    "import statistics\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e6172f-b48a-454d-a7a7-96d8dba9159d",
   "metadata": {},
   "source": [
    "## best param at split 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489efe70-6c2f-4c1c-9b93-86ea9138804c",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4825e475-8be9-4d8e-a66c-ab2c31a9b9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path final test\n",
    "path = \"../Anny_oversampling/DATA/\"\n",
    "train_path = \"{}/train.csv\".format(path)\n",
    "test_path =  \"{}/test.csv\".format(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cb300a3-5b1e-42dc-8d55-1bb1979f41ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # setting split and path\n",
    "# split = 'split5'\n",
    "# path = \"../Anny_oversampling/DATA/\"\n",
    "# train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "# # test_path =  \"{}/{}/test/test_{}.csv\".format(path,split,split)\n",
    "# test_path =  \"{}/test.csv\".format(path)\n",
    "# valid_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07b58ef8-5b0f-4028-86d3-1d97b6af0dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Anny_oversampling/DATA//train.csv\n",
      "(455, 32)\n",
      "(455, 30)\n",
      "['B' 'M']\n",
      "../Anny_oversampling/DATA//test.csv\n",
      "(114, 33)\n",
      "(114, 30)\n",
      "['B' 'M']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10636\\2459194311.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mx_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_val' is not defined"
     ]
    }
   ],
   "source": [
    "print(train_path)\n",
    "# Load the train set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "print(test_path)\n",
    "# Load the test set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# print(valid_path)\n",
    "# # Load the validation set\n",
    "# val_data = pd.read_csv(valid_path)\n",
    "# print(val_data.shape)\n",
    "# x_val = val_data[val_data.columns[2:]]\n",
    "# print(x_val.shape)\n",
    "# y_val = val_data[val_data.columns[1]]\n",
    "# le = LabelEncoder()\n",
    "# y_val = np.array(le.fit_transform(y_val))\n",
    "# print(le.classes_)\n",
    "\n",
    "# StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa13e98-fe0b-4b5a-9c38-188ccaf2f440",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd638e4-88d8-479c-952d-73e3d49a4808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_dist = {\n",
    "#     'n_estimators': [120,130,140],\n",
    "#     'max_features': ['sqrt', 'log2'],\n",
    "#     'max_depth': [2,4,6],\n",
    "#     'min_samples_split': [5,7,9],\n",
    "#     'min_samples_leaf': [1,3,5],\n",
    "#     'bootstrap': [True, False],\n",
    "#     'criterion': ['gini', 'entropy']\n",
    "# }\n",
    "\n",
    "# # Define grid search object\n",
    "# cv_rf = GridSearchCV(RandomForestClassifier(), param_dist)\n",
    "\n",
    "# cv_rf.fit(x_train, y_train)\n",
    "\n",
    "# # save the model\n",
    "# path = 'rf_model/rf_parameter_{}.txt'.format(split)\n",
    "# with open(path, 'w') as f:\n",
    "#     f.write(str(cv_rf.best_params_))\n",
    "#     f.write(str(cv_rf.best_score_))\n",
    "#     print(\"save parameter at {}\".format(path))\n",
    "# joblib.dump(cv_rf, 'rf_model/rf_{}.joblib'.format(split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2580f5-bc13-4f3e-b09e-84ee5a5ffae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {'bootstrap': False, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 3, 'min_samples_split': 7, 'n_estimators': 120}\n",
    "cv_rf = RandomForestClassifier(bootstrap=False, criterion=\"gini\", max_depth=6, max_features='sqrt', min_samples_leaf=3, min_samples_split=7, n_estimators=120)\n",
    "cv_rf.fit(x_train, y_train)\n",
    "# joblib.dump(cv_rf, 'rf_model/rf_best_param2_{}.joblib'.format(split))\n",
    "joblib.dump(cv_rf, 'rf_model/final_models.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb06ecf-aebf-4483-a26a-f0a8d30dabd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Best Parameters using grid search: \\n', cv_rf.best_params_)\n",
    "# print('Best score:', cv_rf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffabcda4-adce-4e8e-b115-c92af4a76b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_rf.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414f67d1-cb2e-44b7-b645-1160288266b8",
   "metadata": {},
   "source": [
    "# evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ace360-edc0-4c50-92c0-2ff7986a4b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split_num = 1\n",
    "# # split = \"split{}\".format(split_num)\n",
    "\n",
    "loaded_model = joblib.load('rf_model/final_models.joblib')\n",
    "# loaded_model = joblib.load('rf_model/rf_best_param2_{}.joblib'.format(split))\n",
    "# loaded_model = joblib.load('rf_model/rf_{}.joblib'.format(split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c732608-d821-4279-9029-efaa39e8b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tn, fp, fn, tp = each_index(cm)\n",
    "def each_index(metrix):\n",
    "    TN = metrix[0][0]\n",
    "    FP = metrix[0][1]\n",
    "    FN = metrix[1][0]\n",
    "    TP = metrix[1][1]\n",
    "    return TN, FP, FN, TP\n",
    "def sensitivity(metrix):\n",
    "    TN, FP, FN, TP = each_index(metrix)\n",
    "    # Calculate sensitivity\n",
    "    sensitivity = TP / (TP + FN) * 100\n",
    "    print(\"Sensitivity: %.2f%%\" % sensitivity)\n",
    "    return sensitivity\n",
    "def specificity(metrix):\n",
    "    TN, FP, FN, TP = each_index(metrix)\n",
    "    # Calculate specificity\n",
    "    specificity = TN / (TN + FP) * 100\n",
    "    print(\"Specificity: %.2f%%\" % specificity)\n",
    "    return specificity\n",
    "def accuracy(metrix):\n",
    "    TN, FP, FN, TP = each_index(metrix)\n",
    "    # Calculate accuracy\n",
    "    accuracy = ((TP + TN) / (TP + TN + FP + FN)) *100\n",
    "    print(\"Accuracy: %.2f%%\" % accuracy)\n",
    "    return accuracy\n",
    "def precision(metrix):\n",
    "    TN, FP, FN, TP = each_index(metrix)\n",
    "    # Calculate accuracy\n",
    "    precision = (TP / (TP + FP)) *100\n",
    "    print(\"Precision: %.2f%%\" % precision)\n",
    "    return precision\n",
    "def f1(metrix):\n",
    "    TN, FP, FN, TP = each_index(metrix)\n",
    "    # Calculate f1\n",
    "    recall = sensitivity(metrix)\n",
    "    pre = precision(metrix)\n",
    "    f1 = ((2*pre*recall) / (pre+recall))\n",
    "    print(\"F1: %.2f%%\" % f1)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44aadc7-c347-4845-a412-2a59ad9efbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "# ############## validate set ################\n",
    "# print(\"############## validate set ################\")\n",
    "# y_pred_val = loaded_model.predict(x_val)\n",
    "\n",
    "# # Confusion matrix\n",
    "# cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "# print('Confusion Matrix')\n",
    "# print('-'*16)\n",
    "# print(cm_val,'\\n')\n",
    "# print('-'*16)\n",
    "\n",
    "# # Calculate score\n",
    "# print(split)\n",
    "# sen_val = sensitivity(cm_val)\n",
    "# spec_val = specificity(cm_val)\n",
    "# acc_val = accuracy(cm_val)\n",
    "# pre_val = precision(cm_val)\n",
    "# f1_score_val = f1(cm_val)\n",
    "    \n",
    "# # plot confusion matrix\n",
    "# label = ['benign','malignant']\n",
    "# plt.figure(figsize=(6, 6))\n",
    "# plt.title(\"Validate set\", fontsize=20)\n",
    "# ax = sns.heatmap(cm_val, cmap=\"rocket_r\", fmt=\".01f\",annot_kws={'size':16}, annot=True, square=True, xticklabels=label, yticklabels=label)\n",
    "# ax.set_ylabel('Actual', fontsize=20)\n",
    "# ax.set_xlabel('Predicted', fontsize=20)\n",
    "# # plt.savefig('rf_model/validate_cm_{}.png'.format(split))\n",
    "# # plt.savefig('rf_model/validate_cm_best_param2_{}.png'.format(split))\n",
    "# plt.show()\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = loaded_model.predict(x_test)\n",
    "# Print the predictions\n",
    "# print(y_pred)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "print(split)\n",
    "sen_test = sensitivity(cm_test)\n",
    "spec_test = specificity(cm_test)\n",
    "acc_test = accuracy(cm_test)\n",
    "pre_test = precision(cm_test)\n",
    "f1_score_test = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "# label = ['benign','malignant']\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.title(\"Test set\", fontsize=20)\n",
    "ax = sns.heatmap(cm_test, cmap=\"rocket_r\", fmt=\".01f\",annot_kws={'size':16}, annot=True, square=True, xticklabels=label, yticklabels=label)\n",
    "ax.set_ylabel('Actual', fontsize=20)\n",
    "ax.set_xlabel('Predicted', fontsize=20)\n",
    "# plt.savefig('rf_model/test_cm_{}.png'.format(split))\n",
    "# plt.savefig('rf_model/test_cm_best_param2_{}.png'.format(split))\n",
    "plt.savefig('rf_model/test_cm_final_models.png')\n",
    "plt.show()\n",
    "    \n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = metrics.roc_curve(y_val,  y_pred_val)\n",
    "auc1 = metrics.roc_auc_score(y_val,  y_pred_val)\n",
    "fpr2, tpr2, thr2 = metrics.roc_curve(y_test,  y_pred_test)\n",
    "auc2 = metrics.roc_auc_score(y_test,  y_pred_test)\n",
    "gmeans2 = np.sqrt(tpr2 * (1-fpr2))\n",
    "ix2 = np.argmax(gmeans2)\n",
    "import sklearn.metrics as metrics\n",
    "    \n",
    "# print('Best Threshold ' + str(i) + ' =%f, G-Mean=%.4f' % (thr[ix], gmeans[ix]))\n",
    "# print('FPR: %.4f, TPR: %.4f' %(fpr[ix], tpr[ix]))\n",
    "# thresholds_ = thr[ix]\n",
    "print(\"---------------------------------------\")\n",
    "# print(\"AUC validate: %.4f\" % auc1)\n",
    "print(\"AUC test: %.4f\" % auc2)\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "# plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc1))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc2))\n",
    "# plt.plot(fpr3,tpr3,label=\"ROC fold 3, auc=\"+str(\"%.4f\" % auc3))\n",
    "# plt.plot(fpr4,tpr4,label=\"ROC fold 4, auc=\"+str(\"%.4f\" % auc4))\n",
    "# plt.plot(fpr5,tpr5,label=\"ROC fold 5, auc=\"+str(\"%.4f\" % auc5))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "\n",
    "plt.legend(loc=4)\n",
    "# plt.savefig('rf_model/ROC_{}.png'.format(split))\n",
    "# plt.savefig('rf_model/ROC_best_param2_{}.png'.format(split))\n",
    "plt.savefig('rf_model/ROC_final_models.png')\n",
    "plt.show()\n",
    "\n",
    "# path = \"rf_model/rf_score_{}.txt\".format(split)\n",
    "path = \"rf_model/rf_score_final_models_{}.txt\".format(split)\n",
    "with open(path, 'w') as f:\n",
    "    # f.write(\"validate\\n\")\n",
    "    # f.write(\"sen:\" + str(sen_val) + \"\\n\")\n",
    "    # f.write(\"spec:\" + str(spec_val) + \"\\n\")\n",
    "    # f.write(\"acc:\" + str(acc_val) + \"\\n\")\n",
    "    # f.write(\"pre:\" + str(pre_val) + \"\\n\")\n",
    "    # f.write(\"f1:\" + str(f1_score_val) + \"\\n\")\n",
    "    f.write(\"\\ntest\\n\")\n",
    "    f.write(\"sen:\" + str(sen_test) + \"\\n\")\n",
    "    f.write(\"spec:\" + str(spec_test) + \"\\n\")\n",
    "    f.write(\"acc:\" + str(acc_test) + \"\\n\")\n",
    "    f.write(\"pre:\" + str(pre_test) + \"\\n\")\n",
    "    f.write(\"f1:\" + str(f1_score_test) + \"\\n\")\n",
    "    f.write(\"\\nROC\\n\")\n",
    "    # f.write(\"validate:\" + str(auc1) + \"\\n\")\n",
    "    f.write(\"test:\" + str(auc2) + \"\\n\")\n",
    "    print(\"save score at {}\".format(path))\n",
    "    \n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc500a-531f-427e-9d15-6e1e7677a738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77852c4-0497-4fb9-9069-07a13b08ae50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517b9fc4-faf0-4443-90f2-2b5a101ed47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a5ada-388c-40f0-a586-83ee4b8640f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2aaa6d5-2448-4e42-b881-f402db56a8da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804b0a05-922b-4531-b393-e827f14be541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36a0079-3c89-4cdc-a15a-b45c767b2403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a61aa3b-9793-4576-a273-8be0a3abfaa8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51030817-2bce-4d80-bcb4-74526bd1ecd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
