{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d654006e",
   "metadata": {},
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "64a62bd3-3688-4c05-8bbc-449730623b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bafa799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import statistics\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aad2269",
   "metadata": {},
   "source": [
    "function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6d245ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tn, fp, fn, tp = each_index(cm)\n",
    "def each_index(metrix):\n",
    "    TN = metrix[0][0]\n",
    "    FP = metrix[0][1]\n",
    "    FN = metrix[1][0]\n",
    "    TP = metrix[1][1]\n",
    "    return TN, FP, FN, TP\n",
    "def sensitivity(metrix):\n",
    "    TN, FP, FN, TP = each_index(metrix)\n",
    "    # Calculate sensitivity\n",
    "    sensitivity = TP / (TP + FN) * 100\n",
    "    print(\"Sensitivity: %.2f%%\" % sensitivity)\n",
    "    return sensitivity\n",
    "def specificity(metrix):\n",
    "    TN, FP, FN, TP = each_index(metrix)\n",
    "    # Calculate specificity\n",
    "    specificity = TN / (TN + FP) * 100\n",
    "    print(\"Specificity: %.2f%%\" % specificity)\n",
    "    return specificity\n",
    "def accuracy(metrix):\n",
    "    TN, FP, FN, TP = each_index(metrix)\n",
    "    # Calculate accuracy\n",
    "    accuracy = ((TP + TN) / (TP + TN + FP + FN)) *100\n",
    "    print(\"Accuracy: %.2f%%\" % accuracy)\n",
    "    return accuracy\n",
    "def precision(metrix):\n",
    "    TN, FP, FN, TP = each_index(metrix)\n",
    "    # Calculate accuracy\n",
    "    precision = (TP / (TP + FP)) *100\n",
    "    print(\"Precision: %.2f%%\" % precision)\n",
    "    return precision\n",
    "def f1(metrix):\n",
    "    TN, FP, FN, TP = each_index(metrix)\n",
    "    # Calculate f1\n",
    "    recall = sensitivity(metrix)\n",
    "    pre = precision(metrix)\n",
    "    f1 = ((2*pre*recall) / (pre+recall))\n",
    "    print(\"F1: %.2f%%\" % f1)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "352eb9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(split):\n",
    "    # setting split and path\n",
    "    path = \"../kitt/DATA_progress3/\"\n",
    "    train_path = \"{}/{}/train/train_oversampling.csv\".format(path,split)\n",
    "    test_path =  \"{}/test.csv\".format(path)\n",
    "    valid_path = \"{}/{}/val/val.csv\".format(path,split)\n",
    "\n",
    "    print(train_path)\n",
    "    # Load the train set\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    print(train_data.shape)\n",
    "    x_train = train_data[train_data.columns[2:]]\n",
    "    print(x_train.shape)\n",
    "    y_train = train_data[train_data.columns[1]]\n",
    "    le = LabelEncoder()\n",
    "    y_train = np.array(le.fit_transform(y_train))\n",
    "    print(le.classes_)\n",
    "    print(test_path)\n",
    "    # Load the test set\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    print(test_data.shape)\n",
    "    x_test = test_data[test_data.columns[2:]]\n",
    "    print(x_test.shape)\n",
    "    y_test = test_data[test_data.columns[1]]\n",
    "    le = LabelEncoder()\n",
    "    y_test = np.array(le.fit_transform(y_test))\n",
    "    print(le.classes_)\n",
    "\n",
    "    print(valid_path)\n",
    "    # Load the validation set\n",
    "    val_data = pd.read_csv(valid_path)\n",
    "    print(val_data.shape)\n",
    "    x_val = val_data[val_data.columns[2:]]\n",
    "    print(x_val.shape)\n",
    "    y_val = val_data[val_data.columns[1]]\n",
    "    le = LabelEncoder()\n",
    "    y_val = np.array(le.fit_transform(y_val))\n",
    "    print(le.classes_)\n",
    "\n",
    "    # StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    x_train = x_train.to_numpy()\n",
    "    x_test = x_test.to_numpy()\n",
    "    x_val = x_val.to_numpy()\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "    x_val = sc.transform(x_val)\n",
    "    \n",
    "    return x_train,y_train,x_test,y_test,x_val,y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01cd536",
   "metadata": {},
   "source": [
    "parameter1 split1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "55930adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../kitt/DATA_progress3//split1/train/train_oversampling.csv\n",
      "(456, 18)\n",
      "(456, 16)\n",
      "['B' 'M']\n",
      "../kitt/DATA_progress3//test.csv\n",
      "(114, 18)\n",
      "(114, 16)\n",
      "['B' 'M']\n",
      "../kitt/DATA_progress3//split1/val/val.csv\n",
      "(91, 18)\n",
      "(91, 16)\n",
      "['B' 'M']\n"
     ]
    }
   ],
   "source": [
    "split_num = 1\n",
    "split = \"split{}\".format(split_num)\n",
    "x_train,y_train,x_test,y_test,x_val,y_val = setup(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "77269bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_score_all(cm_val):\n",
    "    sen_val = sensitivity(cm_val)\n",
    "    spec_val = specificity(cm_val)\n",
    "    acc_val = accuracy(cm_val)\n",
    "    pre_val = precision(cm_val)\n",
    "    f1_score_val = f1(cm_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "416bcf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(cm_val, save=False,which=\"-\"):\n",
    "    class_names = ['benign','malignant']\n",
    "    # Normalize confusion matrix to percentage\n",
    "    cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "    ax.grid(False)\n",
    "    # Add labels\n",
    "    ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "           yticks=np.arange(cm_norm_val.shape[0]),\n",
    "           xticklabels=class_names, yticklabels=class_names)\n",
    "    ax.set_title(which, fontsize=16)\n",
    "    ax.set_ylabel('Actual', fontsize=16)\n",
    "    ax.set_xlabel('Predicted', fontsize=16)\n",
    "    # Add percentage and count values inside plot\n",
    "    thresh = cm_norm_val.max() / 2.\n",
    "    for i in range(cm_norm_val.shape[0]):\n",
    "        for j in range(cm_norm_val.shape[1]):\n",
    "            ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm_norm_val[i, j] > thresh else \"black\",\n",
    "                   fontsize=20)\n",
    "    if save is not False:\n",
    "        save_path = '{}_{}.png'.format(split)\n",
    "        plt.savefig(save_path)\n",
    "        print(\"Save fig at {}\".format(save_path))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0fda80ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ROC():\n",
    "    fpr1, tpr1, thr1 = metrics.roc_curve(y_val,  y_pred_val)\n",
    "    auc1 = metrics.roc_auc_score(y_val,  y_pred_val)\n",
    "    fpr2, tpr2, thr2 = metrics.roc_curve(y_test,  y_pred_test)\n",
    "    auc2 = metrics.roc_auc_score(y_test,  y_pred_test)\n",
    "    gmeans2 = np.sqrt(tpr2 * (1-fpr2))\n",
    "    ix2 = np.argmax(gmeans2)\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"AUC validate: %.4f\" % auc1)\n",
    "    print(\"AUC test: %.4f\" % auc2)\n",
    "    plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc1))\n",
    "    plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc2))\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f245ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    "    \n",
    "def thresholding(y_val, y_pred_val):\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_val,  y_pred_val[:, 1])\n",
    "    # get the best threshold\n",
    "    J = tpr - fpr\n",
    "    ix = np.argmax(J)\n",
    "    best_thresh = thresholds[ix]\n",
    "    print('Best Threshold=%f' % (best_thresh))\n",
    "    print('FPR: %.4f\\nTPR: %.4f' %(fpr[ix], tpr[ix]))\n",
    "    y_pred_val_new = to_labels(y_pred_val[:, 1], best_thresh)\n",
    "    return y_pred_val_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d1cdf345",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(param,split):\n",
    "    #logisticregression/models/param1/lr_model_split1.pkl\n",
    "    model_path = \"../logisticregression/models/param{}/lr_model_split{}.pkl\".format(param,split)\n",
    "    print(model_path)\n",
    "    loaded_model = joblib.load(model_path)\n",
    "\n",
    "    print(\"############## validate set ################\")\n",
    "    y_pred_val_raw = loaded_model.predict_proba(x_val)\n",
    "    y_pred_val = thresholding(y_val, y_pred_val_raw)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "    print('Confusion Matrix')\n",
    "    print('-'*16)\n",
    "    print(cm_val,'\\n')\n",
    "    print('-'*16)\n",
    "\n",
    "    # Calculate score\n",
    "    print(split)\n",
    "    cal_score_all(cm_val)\n",
    "    \n",
    "    # plot confusion matrix\n",
    "    plot_cm(cm_val, which=\"Validate set\")\n",
    "    \n",
    "    # ################# test set ##################\n",
    "    label = ['benign','malignant']\n",
    "    print(\"################# test set ##################\")\n",
    "    y_pred_test_raw = loaded_model.predict_proba(x_test)\n",
    "    y_pred_test = thresholding(y_test, y_pred_test_raw)\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "    print('Confusion Matrix')\n",
    "    print('-'*16)\n",
    "    print(cm_test,'\\n')\n",
    "    print('-'*16)\n",
    "\n",
    "    # Calculate score\n",
    "    print(split)\n",
    "    cal_score_all(cm_test)\n",
    "\n",
    "    # plot confusion matrix\n",
    "    plot_cm(cm_test,which=\"Test set\")\n",
    "\n",
    "    ################## plot ROC curve ########################\n",
    "    fpr1, tpr1, thr1 = metrics.roc_curve(y_val,  y_pred_val_raw[:,1])\n",
    "    auc1 = metrics.roc_auc_score(y_val,  y_pred_val_raw[:,1])*100\n",
    "    fpr2, tpr2, thr2 = metrics.roc_curve(y_test,  y_pred_test_raw[:,1])\n",
    "    auc2 = metrics.roc_auc_score(y_test,  y_pred_test_raw[:,1])*100\n",
    "    gmeans2 = np.sqrt(tpr2 * (1-fpr2))\n",
    "    ix2 = np.argmax(gmeans2)\n",
    "    print(\"---------------------------------------\")\n",
    "    print(\"AUC validate: %.2f%%\" % auc1)\n",
    "    print(\"AUC test: %.2f%%\" % auc2)\n",
    "    plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.2f%%\" % auc1))\n",
    "    plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.2f%%\" % auc2))\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.show()\n",
    "    \n",
    "    return cm_val,cm_test,auc1,auc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "753f273d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../logisticregression/models/param1/lr_model_split1.pkl\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m split \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m      2\u001b[0m param \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m----> 3\u001b[0m param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test \u001b[39m=\u001b[39m evaluate(param,split)\n",
      "Cell \u001b[1;32mIn[65], line 5\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(param, split)\u001b[0m\n\u001b[0;32m      3\u001b[0m model_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../logisticregression/models/param\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/lr_model_split\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.pkl\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(param,split)\n\u001b[0;32m      4\u001b[0m \u001b[39mprint\u001b[39m(model_path)\n\u001b[1;32m----> 5\u001b[0m loaded_model \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(model_path)\n\u001b[0;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m############## validate set ################\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m y_pred_val_raw \u001b[39m=\u001b[39m loaded_model\u001b[39m.\u001b[39mpredict_proba(x_val)\n",
      "File \u001b[1;32mc:\\Users\\warathep\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py:587\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    582\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    583\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    584\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    585\u001b[0m                 \u001b[39mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 587\u001b[0m             obj \u001b[39m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[0;32m    588\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\warathep\\anaconda3\\lib\\site-packages\\joblib\\numpy_pickle.py:506\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    504\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 506\u001b[0m     obj \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[0;32m    507\u001b[0m     \u001b[39mif\u001b[39;00m unpickler\u001b[39m.\u001b[39mcompat_mode:\n\u001b[0;32m    508\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been generated with a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    509\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mjoblib version less than 0.10. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    510\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPlease regenerate this pickle file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    511\u001b[0m                       \u001b[39m%\u001b[39m filename,\n\u001b[0;32m    512\u001b[0m                       \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\warathep\\anaconda3\\lib\\pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1213\u001b[0m         dispatch[key[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39m)\n\u001b[0;32m   1214\u001b[0m \u001b[39mexcept\u001b[39;00m _Stop \u001b[39mas\u001b[39;00m stopinst:\n\u001b[0;32m   1215\u001b[0m     \u001b[39mreturn\u001b[39;00m stopinst\u001b[39m.\u001b[39mvalue\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "param = 1\n",
    "split = 1\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe46a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 1\n",
    "split = 2\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be11faf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 1\n",
    "split = 3\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8922d4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 1\n",
    "split = 4\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef738c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 1\n",
    "split = 5\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea7d407",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 2\n",
    "split = 1\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbac0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 2\n",
    "split = 2\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cf42fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 2\n",
    "split = 3\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ecea68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 2\n",
    "split = 4\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f080a341",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 2\n",
    "split = 5\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b17efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 3\n",
    "split = 1\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1829defd",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 3\n",
    "split = 2\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 3\n",
    "split = 4\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd49c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 3\n",
    "split = 5\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add0c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 4\n",
    "split = 1\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db836fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 4\n",
    "split = 2\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da3e267",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 4\n",
    "split = 3\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec21948",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 4\n",
    "split = 4\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af56529",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 4\n",
    "split = 5\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4f4374",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 5\n",
    "split = 1\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c72b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 5\n",
    "split = 2\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c55821",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 5\n",
    "split = 3\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c8efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 5\n",
    "split = 4\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85c004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = 5\n",
    "split = 5\n",
    "param1_split1_cm_val, param1_split1_cm_test, param1_split1_AUC_val, param1_split1_AUC_test = evaluate(param,split)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "23bf0724a01b6ea9814e66f76182ea78c0ee849a72ca257c0e116bf83bb4960a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
