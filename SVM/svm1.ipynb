{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d654006e",
   "metadata": {},
   "source": [
    "import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bafa799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import statistics\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3aad2269",
   "metadata": {},
   "source": [
    "function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d245ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tn, fp, fn, tp = each_index(cm)\n",
    "def each_index(metrix):\n",
    "    TN = metrix[0][0]\n",
    "    FP = metrix[0][1]\n",
    "    FN = metrix[1][0]\n",
    "    TP = metrix[1][1]\n",
    "    return TN, FP, FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b7e1465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(metrix):\n",
    "    TN, FP, FN, TP = each_index(metrix)\n",
    "    # Calculate sensitivity\n",
    "    sensitivity = TP / (TP + FN) * 100\n",
    "    print(\"Sensitivity: %.2f%%\" % sensitivity)\n",
    "    return sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3aa929a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def specificity(metrix):\n",
    "    TN, FP, FN, TP = each_index(metrix)\n",
    "    # Calculate specificity\n",
    "    specificity = TN / (TN + FP) * 100\n",
    "    print(\"Specificity: %.2f%%\" % specificity)\n",
    "    return specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4935d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(metrix):\n",
    "    TN, FP, FN, TP = each_index(metrix)\n",
    "    # Calculate accuracy\n",
    "    accuracy = ((TP + TN) / (TP + TN + FP + FN)) *100\n",
    "    print(\"Accuracy: %.2f%%\" % accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "583a8586",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(metrix):\n",
    "    TN, FP, FN, TP = each_index(metrix)\n",
    "    # Calculate accuracy\n",
    "    precision = (TP / (TP + FP)) *100\n",
    "    print(\"Precision: %.2f%%\" % precision)\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52e8b846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(metrix):\n",
    "    TN, FP, FN, TP = each_index(metrix)\n",
    "    # Calculate f1\n",
    "    recall = sensitivity(metrix)\n",
    "    pre = precision(metrix)\n",
    "    f1 = ((2*pre*recall) / (pre+recall))\n",
    "    print(\"F1: %.2f%%\" % f1)\n",
    "    return f1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a01cd536",
   "metadata": {},
   "source": [
    "parameter1 split1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e594155a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(518, 32)\n",
      "(518, 30)\n",
      "['B' 'M']\n",
      "(114, 33)\n",
      "(114, 30)\n",
      "['B' 'M']\n",
      "(91, 32)\n",
      "(91, 30)\n",
      "['B' 'M']\n",
      "split1\n",
      "train positive:    259\n",
      "validate positive: 39\n"
     ]
    }
   ],
   "source": [
    "# setting split and path\n",
    "split = 'split1'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "90b78b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9888888888888889\n",
      "Best Hyperparameters: {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# grid search svm model\n",
    "\n",
    "# define model\n",
    "model = SVC()\n",
    "\n",
    "# define parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, param_grid, refit = True)\n",
    "\n",
    "# execute search\n",
    "result = search.fit(x_val, y_val)\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f22f98fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the individual models\n",
    "model = SVC(C=10, gamma=0.001, kernel='rbf')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param1/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "afec72b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split1\n",
      "############## validate set ################\n",
      "Confusion Matrix\n",
      "----------------\n",
      "[[47  5]\n",
      " [ 1 38]] \n",
      "\n",
      "----------------\n",
      "Sensitivity: 97.44%\n",
      "Specificity: 90.38%\n",
      "Accuracy: 93.41%\n",
      "Precision: 88.37%\n",
      "Sensitivity: 97.44%\n",
      "Precision: 88.37%\n",
      "F1: 92.68%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'rocket_r' is not a valid value for cmap; supported values are 'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'winter', 'winter_r'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m# Create plot\u001b[39;00m\n\u001b[0;32m     25\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots()\n\u001b[1;32m---> 26\u001b[0m im \u001b[39m=\u001b[39m ax\u001b[39m.\u001b[39;49mimshow(cm_norm_val, interpolation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnearest\u001b[39;49m\u001b[39m'\u001b[39;49m, cmap\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrocket_r\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     27\u001b[0m ax\u001b[39m.\u001b[39mgrid(\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m \u001b[39m# Add labels\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:1442\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m   1440\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   1441\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1442\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(sanitize_sequence, args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1444\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1445\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[0;32m   1446\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:5658\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5656\u001b[0m     aspect \u001b[39m=\u001b[39m mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39mimage.aspect\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m   5657\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m-> 5658\u001b[0m im \u001b[39m=\u001b[39m mimage\u001b[39m.\u001b[39mAxesImage(\u001b[39mself\u001b[39m, cmap\u001b[39m=\u001b[39mcmap, norm\u001b[39m=\u001b[39mnorm,\n\u001b[0;32m   5659\u001b[0m                       interpolation\u001b[39m=\u001b[39minterpolation, origin\u001b[39m=\u001b[39morigin,\n\u001b[0;32m   5660\u001b[0m                       extent\u001b[39m=\u001b[39mextent, filternorm\u001b[39m=\u001b[39mfilternorm,\n\u001b[0;32m   5661\u001b[0m                       filterrad\u001b[39m=\u001b[39mfilterrad, resample\u001b[39m=\u001b[39mresample,\n\u001b[0;32m   5662\u001b[0m                       interpolation_stage\u001b[39m=\u001b[39minterpolation_stage,\n\u001b[0;32m   5663\u001b[0m                       \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   5665\u001b[0m im\u001b[39m.\u001b[39mset_data(X)\n\u001b[0;32m   5666\u001b[0m im\u001b[39m.\u001b[39mset_alpha(alpha)\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:454\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m name_idx:\n\u001b[0;32m    449\u001b[0m     warn_deprecated(\n\u001b[0;32m    450\u001b[0m         since, message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPassing the \u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m%(obj_type)s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    451\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpositionally is deprecated since Matplotlib \u001b[39m\u001b[39m%(since)s\u001b[39;00m\u001b[39m; the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mparameter will become keyword-only \u001b[39m\u001b[39m%(removal)s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    453\u001b[0m         name\u001b[39m=\u001b[39mname, obj_type\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 454\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\lib\\site-packages\\matplotlib\\image.py:922\u001b[0m, in \u001b[0;36mAxesImage.__init__\u001b[1;34m(self, ax, cmap, norm, interpolation, origin, extent, filternorm, filterrad, resample, interpolation_stage, **kwargs)\u001b[0m\n\u001b[0;32m    905\u001b[0m \u001b[39m@_api\u001b[39m\u001b[39m.\u001b[39mmake_keyword_only(\u001b[39m\"\u001b[39m\u001b[39m3.6\u001b[39m\u001b[39m\"\u001b[39m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcmap\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    906\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, ax,\n\u001b[0;32m    907\u001b[0m              cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    917\u001b[0m              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    918\u001b[0m              ):\n\u001b[0;32m    920\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extent \u001b[39m=\u001b[39m extent\n\u001b[1;32m--> 922\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m    923\u001b[0m         ax,\n\u001b[0;32m    924\u001b[0m         cmap\u001b[39m=\u001b[39mcmap,\n\u001b[0;32m    925\u001b[0m         norm\u001b[39m=\u001b[39mnorm,\n\u001b[0;32m    926\u001b[0m         interpolation\u001b[39m=\u001b[39minterpolation,\n\u001b[0;32m    927\u001b[0m         origin\u001b[39m=\u001b[39morigin,\n\u001b[0;32m    928\u001b[0m         filternorm\u001b[39m=\u001b[39mfilternorm,\n\u001b[0;32m    929\u001b[0m         filterrad\u001b[39m=\u001b[39mfilterrad,\n\u001b[0;32m    930\u001b[0m         resample\u001b[39m=\u001b[39mresample,\n\u001b[0;32m    931\u001b[0m         interpolation_stage\u001b[39m=\u001b[39minterpolation_stage,\n\u001b[0;32m    932\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    933\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\lib\\site-packages\\matplotlib\\image.py:260\u001b[0m, in \u001b[0;36m_ImageBase.__init__\u001b[1;34m(self, ax, cmap, norm, interpolation, origin, filternorm, filterrad, resample, interpolation_stage, **kwargs)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, ax,\n\u001b[0;32m    248\u001b[0m              cmap\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    249\u001b[0m              norm\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    257\u001b[0m              \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    258\u001b[0m              ):\n\u001b[0;32m    259\u001b[0m     martist\u001b[39m.\u001b[39mArtist\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 260\u001b[0m     cm\u001b[39m.\u001b[39;49mScalarMappable\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, norm, cmap)\n\u001b[0;32m    261\u001b[0m     \u001b[39mif\u001b[39;00m origin \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m         origin \u001b[39m=\u001b[39m mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39mimage.origin\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\lib\\site-packages\\matplotlib\\cm.py:400\u001b[0m, in \u001b[0;36mScalarMappable.__init__\u001b[1;34m(self, norm, cmap)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mset_norm(norm)  \u001b[39m# The Normalize instance of this ScalarMappable.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcmap \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m  \u001b[39m# So that the setter knows we're initializing.\u001b[39;00m\n\u001b[1;32m--> 400\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_cmap(cmap)  \u001b[39m# The Colormap instance of this ScalarMappable.\u001b[39;00m\n\u001b[0;32m    401\u001b[0m \u001b[39m#: The last colorbar associated with this ScalarMappable. May be None.\u001b[39;00m\n\u001b[0;32m    402\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolorbar \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\lib\\site-packages\\matplotlib\\cm.py:585\u001b[0m, in \u001b[0;36mScalarMappable.set_cmap\u001b[1;34m(self, cmap)\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[39mSet the colormap for luminance data.\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    581\u001b[0m \u001b[39mcmap : `.Colormap` or str or None\u001b[39;00m\n\u001b[0;32m    582\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    583\u001b[0m in_init \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcmap \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcmap \u001b[39m=\u001b[39m _ensure_cmap(cmap)\n\u001b[0;32m    586\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m in_init:\n\u001b[0;32m    587\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchanged()\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\lib\\site-packages\\matplotlib\\cm.py:723\u001b[0m, in \u001b[0;36m_ensure_cmap\u001b[1;34m(cmap)\u001b[0m\n\u001b[0;32m    720\u001b[0m cmap_name \u001b[39m=\u001b[39m cmap \u001b[39mif\u001b[39;00m cmap \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m mpl\u001b[39m.\u001b[39mrcParams[\u001b[39m\"\u001b[39m\u001b[39mimage.cmap\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    721\u001b[0m \u001b[39m# use check_in_list to ensure type stability of the exception raised by\u001b[39;00m\n\u001b[0;32m    722\u001b[0m \u001b[39m# the internal usage of this (ValueError vs KeyError)\u001b[39;00m\n\u001b[1;32m--> 723\u001b[0m _api\u001b[39m.\u001b[39;49mcheck_in_list(\u001b[39msorted\u001b[39;49m(_colormaps), cmap\u001b[39m=\u001b[39;49mcmap_name)\n\u001b[0;32m    724\u001b[0m \u001b[39mreturn\u001b[39;00m mpl\u001b[39m.\u001b[39mcolormaps[cmap_name]\n",
      "File \u001b[1;32mc:\\Users\\acer\\anaconda3\\lib\\site-packages\\matplotlib\\_api\\__init__.py:131\u001b[0m, in \u001b[0;36mcheck_in_list\u001b[1;34m(_values, _print_supported_values, **kwargs)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m _print_supported_values:\n\u001b[0;32m    130\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m; supported values are \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mmap\u001b[39m(\u001b[39mrepr\u001b[39m, values))\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 131\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: 'rocket_r' is not a valid value for cmap; supported values are 'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'winter', 'winter_r'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split1 = sensitivity(cm_test)\n",
    "spec_test_split1 = specificity(cm_test)\n",
    "acc_test_split1 = accuracy(cm_test)\n",
    "pre_test_split1 = precision(cm_test)\n",
    "f1_test_split1 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split1 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split1)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split1))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c5ec0a",
   "metadata": {},
   "source": [
    "split2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca7bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split2'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param1/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be203a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split2 = sensitivity(cm_test)\n",
    "spec_test_split2 = specificity(cm_test)\n",
    "acc_test_split2 = accuracy(cm_test)\n",
    "pre_test_split2 = precision(cm_test)\n",
    "f1_test_split2 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split2 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split2)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split2))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde69e32",
   "metadata": {},
   "source": [
    "split3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37c8908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split3'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param1/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71342927",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split3 = sensitivity(cm_test)\n",
    "spec_test_split3 = specificity(cm_test)\n",
    "acc_test_split3 = accuracy(cm_test)\n",
    "pre_test_split3 = precision(cm_test)\n",
    "f1_test_split3 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split3 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split3)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split3))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622066b5",
   "metadata": {},
   "source": [
    "split4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b505d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split4'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param1/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d0f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split4 = sensitivity(cm_test)\n",
    "spec_test_split4 = specificity(cm_test)\n",
    "acc_test_split4 = accuracy(cm_test)\n",
    "pre_test_split4 = precision(cm_test)\n",
    "f1_test_split4 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split4 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split4)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split4))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618dcdd8",
   "metadata": {},
   "source": [
    "split5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ee8bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split5'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param1/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e032670c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split5 = sensitivity(cm_test)\n",
    "spec_test_split5 = specificity(cm_test)\n",
    "acc_test_split5 = accuracy(cm_test)\n",
    "pre_test_split5 = precision(cm_test)\n",
    "f1_test_split5 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split5 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split5)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split5))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb8ed102",
   "metadata": {},
   "source": [
    "overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6afdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_values = []\n",
    "\n",
    "sensitivity_values.append(sen_test_split1)\n",
    "sensitivity_values.append(sen_test_split2)\n",
    "sensitivity_values.append(sen_test_split3)\n",
    "sensitivity_values.append(sen_test_split4)\n",
    "sensitivity_values.append(sen_test_split5)\n",
    "\n",
    "print(sensitivity_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_sensitivity = statistics.mean(sensitivity_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "sensitivity_sd = statistics.stdev(sensitivity_values)\n",
    "\n",
    "print(\"Mean Sensitivity:\", mean_sensitivity)\n",
    "print(\"Sensitivity Standard Deviation:\", sensitivity_sd)\n",
    "\n",
    "# Print mean sensitivity with standard deviation\n",
    "print(\"Overall Sensitivity: %.2f  %.2f%%\" % (mean_sensitivity, sensitivity_sd))\n",
    "\n",
    "specificity_values = []\n",
    "\n",
    "specificity_values.append(spec_test_split1)\n",
    "specificity_values.append(spec_test_split2)\n",
    "specificity_values.append(spec_test_split3)\n",
    "specificity_values.append(spec_test_split4)\n",
    "specificity_values.append(spec_test_split5)\n",
    "    \n",
    "print(specificity_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_specificity = statistics.mean(specificity_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "specificity_sd = statistics.stdev(specificity_values)\n",
    "\n",
    "print(\"Mean Specificity:\", mean_specificity)\n",
    "print(\"Specificity Standard Deviation:\", specificity_sd)\n",
    "\n",
    "# Print mean specificity with standard deviation\n",
    "print(\"Overall Specificity: %.2f  %.2f%%\" % (mean_specificity, specificity_sd))\n",
    "\n",
    "accuracy_values = []\n",
    "\n",
    "accuracy_values.append(acc_test_split1)\n",
    "accuracy_values.append(acc_test_split2)\n",
    "accuracy_values.append(acc_test_split3)\n",
    "accuracy_values.append(acc_test_split4)\n",
    "accuracy_values.append(acc_test_split5)\n",
    "    \n",
    "print(accuracy_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_accuracy = statistics.mean(accuracy_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "accuracy_sd = statistics.stdev(accuracy_values)\n",
    "\n",
    "print(\"Mean accuracy:\", mean_accuracy)\n",
    "print(\"accuracy Standard Deviation:\", accuracy_sd)\n",
    "\n",
    "# Print mean accuracy with standard deviation\n",
    "print(\"Overall accuracy: %.2f  %.2f%%\" % (mean_accuracy, accuracy_sd))\n",
    "\n",
    "precision_values = []\n",
    "\n",
    "precision_values.append(pre_test_split1)\n",
    "precision_values.append(pre_test_split2)\n",
    "precision_values.append(pre_test_split3)\n",
    "precision_values.append(pre_test_split4)\n",
    "precision_values.append(pre_test_split5)\n",
    "    \n",
    "print(precision_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_precision = statistics.mean(precision_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "precision_sd = statistics.stdev(precision_values)\n",
    "\n",
    "print(\"Mean precision:\", mean_precision)\n",
    "print(\"precision Standard Deviation:\", precision_sd)\n",
    "\n",
    "# Print mean specificity with standard deviation\n",
    "print(\"Overall precision: %.2f  %.2f%%\" % (mean_precision, precision_sd))\n",
    "\n",
    "f1_values = []\n",
    "\n",
    "f1_values.append(f1_test_split1)\n",
    "f1_values.append(f1_test_split2)\n",
    "f1_values.append(f1_test_split3)\n",
    "f1_values.append(f1_test_split4)\n",
    "f1_values.append(f1_test_split5)\n",
    "    \n",
    "print(f1_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_f1 = statistics.mean(f1_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "f1_sd = statistics.stdev(f1_values)\n",
    "\n",
    "print(\"Mean f1:\", mean_f1)\n",
    "print(\"f1 Standard Deviation:\", f1_sd)\n",
    "\n",
    "# Print mean specificity with standard deviation\n",
    "print(\"Overall f1: %.2f  %.2f%%\" % (mean_f1, f1_sd))\n",
    "\n",
    "auc_values = []\n",
    "\n",
    "auc_values.append(auc_test_split1)\n",
    "auc_values.append(auc_test_split2)\n",
    "auc_values.append(auc_test_split3)\n",
    "auc_values.append(auc_test_split4)\n",
    "auc_values.append(auc_test_split5)\n",
    "    \n",
    "print(auc_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_auc = statistics.mean(auc_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "auc_sd = statistics.stdev(auc_values)\n",
    "\n",
    "print(\"Mean auc:\", mean_auc)\n",
    "print(\"auc Standard Deviation:\", auc_sd)\n",
    "\n",
    "# Print mean auc with standard deviation\n",
    "print(\"Overall auc: %.2f  %.2f%%\" % (mean_auc, auc_sd))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d0c02bb",
   "metadata": {},
   "source": [
    "parameter2 split2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530ad864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split2'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b0a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search svm model\n",
    "\n",
    "# define model\n",
    "model = SVC()\n",
    "\n",
    "# define parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, param_grid, refit = True)\n",
    "\n",
    "# execute search\n",
    "result = search.fit(x_val, y_val)\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56889fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the individual models\n",
    "model = SVC(C=10, gamma=0.01, kernel='sigmoid')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param2/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca5b1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split2 = sensitivity(cm_test)\n",
    "spec_test_split2 = specificity(cm_test)\n",
    "acc_test_split2 = accuracy(cm_test)\n",
    "pre_test_split2 = precision(cm_test)\n",
    "f1_test_split2 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split2 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split2)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split2))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "842ff1ac",
   "metadata": {},
   "source": [
    "split1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b35d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split1'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param2/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7f85aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split1 = sensitivity(cm_test)\n",
    "spec_test_split1 = specificity(cm_test)\n",
    "acc_test_split1 = accuracy(cm_test)\n",
    "pre_test_split1 = precision(cm_test)\n",
    "f1_test_split1 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split1 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split1)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split1))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2dc2f1c",
   "metadata": {},
   "source": [
    "split3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf889e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split3'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param2/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3b5bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split3 = sensitivity(cm_test)\n",
    "spec_test_split3 = specificity(cm_test)\n",
    "acc_test_split3 = accuracy(cm_test)\n",
    "pre_test_split3 = precision(cm_test)\n",
    "f1_test_split3 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split3 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split3)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split3))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb45d15e",
   "metadata": {},
   "source": [
    "split4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a132de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split4'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param2/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c384450",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split4 = sensitivity(cm_test)\n",
    "spec_test_split4 = specificity(cm_test)\n",
    "acc_test_split4 = accuracy(cm_test)\n",
    "pre_test_split4 = precision(cm_test)\n",
    "f1_test_split4 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split4 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split4)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split4))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9197afe5",
   "metadata": {},
   "source": [
    "split5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f06378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split5'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param2/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcae51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split5 = sensitivity(cm_test)\n",
    "spec_test_split5 = specificity(cm_test)\n",
    "acc_test_split5 = accuracy(cm_test)\n",
    "pre_test_split5 = precision(cm_test)\n",
    "f1_test_split5 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split5 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split5)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split5))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a30eb283",
   "metadata": {},
   "source": [
    "overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbb2de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split1 = np.array([[46, 0], [3, 65]])\n",
    "test_split2 = np.array([[46, 0], [6, 62]])\n",
    "test_split3 = np.array([[46, 0], [5, 63]])\n",
    "test_split4 = np.array([[46, 0], [4, 64]])\n",
    "test_split5 = np.array([[46, 0], [3, 65]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37fc5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_test = test_split1 + test_split2 + test_split3 + test_split4 + test_split5\n",
    "print(overall_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d628198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = overall_test.astype('float') / overall_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(overall_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760effad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_values = []\n",
    "\n",
    "sensitivity_values.append(sen_test_split1)\n",
    "sensitivity_values.append(sen_test_split2)\n",
    "sensitivity_values.append(sen_test_split3)\n",
    "sensitivity_values.append(sen_test_split4)\n",
    "sensitivity_values.append(sen_test_split5)\n",
    "\n",
    "print(sensitivity_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_sensitivity = statistics.mean(sensitivity_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "sensitivity_sd = statistics.stdev(sensitivity_values)\n",
    "\n",
    "print(\"Mean Sensitivity:\", mean_sensitivity)\n",
    "print(\"Sensitivity Standard Deviation:\", sensitivity_sd)\n",
    "\n",
    "# Print mean sensitivity with standard deviation\n",
    "print(\"Overall Sensitivity: %.2f  %.2f%%\" % (mean_sensitivity, sensitivity_sd))\n",
    "\n",
    "specificity_values = []\n",
    "\n",
    "specificity_values.append(spec_test_split1)\n",
    "specificity_values.append(spec_test_split2)\n",
    "specificity_values.append(spec_test_split3)\n",
    "specificity_values.append(spec_test_split4)\n",
    "specificity_values.append(spec_test_split5)\n",
    "    \n",
    "print(specificity_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_specificity = statistics.mean(specificity_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "specificity_sd = statistics.stdev(specificity_values)\n",
    "\n",
    "print(\"Mean Specificity:\", mean_specificity)\n",
    "print(\"Specificity Standard Deviation:\", specificity_sd)\n",
    "\n",
    "# Print mean specificity with standard deviation\n",
    "print(\"Overall Specificity: %.2f  %.2f%%\" % (mean_specificity, specificity_sd))\n",
    "\n",
    "accuracy_values = []\n",
    "\n",
    "accuracy_values.append(acc_test_split1)\n",
    "accuracy_values.append(acc_test_split2)\n",
    "accuracy_values.append(acc_test_split3)\n",
    "accuracy_values.append(acc_test_split4)\n",
    "accuracy_values.append(acc_test_split5)\n",
    "    \n",
    "print(accuracy_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_accuracy = statistics.mean(accuracy_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "accuracy_sd = statistics.stdev(accuracy_values)\n",
    "\n",
    "print(\"Mean accuracy:\", mean_accuracy)\n",
    "print(\"accuracy Standard Deviation:\", accuracy_sd)\n",
    "\n",
    "# Print mean accuracy with standard deviation\n",
    "print(\"Overall accuracy: %.2f  %.2f%%\" % (mean_accuracy, accuracy_sd))\n",
    "\n",
    "precision_values = []\n",
    "\n",
    "precision_values.append(pre_test_split1)\n",
    "precision_values.append(pre_test_split2)\n",
    "precision_values.append(pre_test_split3)\n",
    "precision_values.append(pre_test_split4)\n",
    "precision_values.append(pre_test_split5)\n",
    "    \n",
    "print(precision_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_precision = statistics.mean(precision_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "precision_sd = statistics.stdev(precision_values)\n",
    "\n",
    "print(\"Mean precision:\", mean_precision)\n",
    "print(\"precision Standard Deviation:\", precision_sd)\n",
    "\n",
    "# Print mean specificity with standard deviation\n",
    "print(\"Overall precision: %.2f  %.2f%%\" % (mean_precision, precision_sd))\n",
    "\n",
    "f1_values = []\n",
    "\n",
    "f1_values.append(f1_test_split1)\n",
    "f1_values.append(f1_test_split2)\n",
    "f1_values.append(f1_test_split3)\n",
    "f1_values.append(f1_test_split4)\n",
    "f1_values.append(f1_test_split5)\n",
    "    \n",
    "print(f1_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_f1 = statistics.mean(f1_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "f1_sd = statistics.stdev(f1_values)\n",
    "\n",
    "print(\"Mean f1:\", mean_f1)\n",
    "print(\"f1 Standard Deviation:\", f1_sd)\n",
    "\n",
    "# Print mean specificity with standard deviation\n",
    "print(\"Overall f1: %.2f  %.2f%%\" % (mean_f1, f1_sd))\n",
    "\n",
    "auc_values = []\n",
    "\n",
    "auc_values.append(auc_test_split1)\n",
    "auc_values.append(auc_test_split2)\n",
    "auc_values.append(auc_test_split3)\n",
    "auc_values.append(auc_test_split4)\n",
    "auc_values.append(auc_test_split5)\n",
    "    \n",
    "print(auc_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_auc = statistics.mean(auc_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "auc_sd = statistics.stdev(auc_values)\n",
    "\n",
    "print(\"Mean auc:\", mean_auc)\n",
    "print(\"auc Standard Deviation:\", auc_sd)\n",
    "\n",
    "# Print mean auc with standard deviation\n",
    "print(\"Overall auc: %.2f  %.2f%%\" % (mean_auc, auc_sd))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2aa58b7",
   "metadata": {},
   "source": [
    "parameter3 split3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d456ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split3'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406f504a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search svm model\n",
    "\n",
    "# define model\n",
    "model = SVC()\n",
    "\n",
    "# define parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, param_grid, refit = True)\n",
    "\n",
    "# execute search\n",
    "result = search.fit(x_val, y_val)\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e45dcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the individual models\n",
    "model = SVC(C=0.1, gamma=0.1, kernel='sigmoid')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param3/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d4390b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split3 = sensitivity(cm_test)\n",
    "spec_test_split3 = specificity(cm_test)\n",
    "acc_test_split3 = accuracy(cm_test)\n",
    "pre_test_split3 = precision(cm_test)\n",
    "f1_test_split3 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split3 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split3)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split3))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44019e87",
   "metadata": {},
   "source": [
    "split1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split1'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param3/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bf45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split1 = sensitivity(cm_test)\n",
    "spec_test_split1 = specificity(cm_test)\n",
    "acc_test_split1 = accuracy(cm_test)\n",
    "pre_test_split1 = precision(cm_test)\n",
    "f1_test_split1 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split1 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split1)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split1))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7cd0d1ce",
   "metadata": {},
   "source": [
    "split2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efed21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split2'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param3/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1352d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split2 = sensitivity(cm_test)\n",
    "spec_test_split2 = specificity(cm_test)\n",
    "acc_test_split2 = accuracy(cm_test)\n",
    "pre_test_split2 = precision(cm_test)\n",
    "f1_test_split2 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split2 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split2)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split2))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b42d762",
   "metadata": {},
   "source": [
    "split4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633d2461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split4'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param3/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5828d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split4 = sensitivity(cm_test)\n",
    "spec_test_split4 = specificity(cm_test)\n",
    "acc_test_split4 = accuracy(cm_test)\n",
    "pre_test_split4 = precision(cm_test)\n",
    "f1_test_split4 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split4 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split4)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split4))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ad36ddb6",
   "metadata": {},
   "source": [
    "split5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc42f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split5'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param3/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9d4e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split5 = sensitivity(cm_test)\n",
    "spec_test_split5 = specificity(cm_test)\n",
    "acc_test_split5 = accuracy(cm_test)\n",
    "pre_test_split5 = precision(cm_test)\n",
    "f1_test_split5 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split5 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split5)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split5))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd75ee6d",
   "metadata": {},
   "source": [
    "overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff594fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_values = []\n",
    "\n",
    "sensitivity_values.append(sen_test_split1)\n",
    "sensitivity_values.append(sen_test_split2)\n",
    "sensitivity_values.append(sen_test_split3)\n",
    "sensitivity_values.append(sen_test_split4)\n",
    "sensitivity_values.append(sen_test_split5)\n",
    "\n",
    "print(sensitivity_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_sensitivity = statistics.mean(sensitivity_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "sensitivity_sd = statistics.stdev(sensitivity_values)\n",
    "\n",
    "print(\"Mean Sensitivity:\", mean_sensitivity)\n",
    "print(\"Sensitivity Standard Deviation:\", sensitivity_sd)\n",
    "\n",
    "# Print mean sensitivity with standard deviation\n",
    "print(\"Overall Sensitivity: %.2f  %.2f%%\" % (mean_sensitivity, sensitivity_sd))\n",
    "\n",
    "specificity_values = []\n",
    "\n",
    "specificity_values.append(spec_test_split1)\n",
    "specificity_values.append(spec_test_split2)\n",
    "specificity_values.append(spec_test_split3)\n",
    "specificity_values.append(spec_test_split4)\n",
    "specificity_values.append(spec_test_split5)\n",
    "    \n",
    "print(specificity_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_specificity = statistics.mean(specificity_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "specificity_sd = statistics.stdev(specificity_values)\n",
    "\n",
    "print(\"Mean Specificity:\", mean_specificity)\n",
    "print(\"Specificity Standard Deviation:\", specificity_sd)\n",
    "\n",
    "# Print mean specificity with standard deviation\n",
    "print(\"Overall Specificity: %.2f  %.2f%%\" % (mean_specificity, specificity_sd))\n",
    "\n",
    "accuracy_values = []\n",
    "\n",
    "accuracy_values.append(acc_test_split1)\n",
    "accuracy_values.append(acc_test_split2)\n",
    "accuracy_values.append(acc_test_split3)\n",
    "accuracy_values.append(acc_test_split4)\n",
    "accuracy_values.append(acc_test_split5)\n",
    "    \n",
    "print(accuracy_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_accuracy = statistics.mean(accuracy_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "accuracy_sd = statistics.stdev(accuracy_values)\n",
    "\n",
    "print(\"Mean accuracy:\", mean_accuracy)\n",
    "print(\"accuracy Standard Deviation:\", accuracy_sd)\n",
    "\n",
    "# Print mean accuracy with standard deviation\n",
    "print(\"Overall accuracy: %.2f  %.2f%%\" % (mean_accuracy, accuracy_sd))\n",
    "\n",
    "precision_values = []\n",
    "\n",
    "precision_values.append(pre_test_split1)\n",
    "precision_values.append(pre_test_split2)\n",
    "precision_values.append(pre_test_split3)\n",
    "precision_values.append(pre_test_split4)\n",
    "precision_values.append(pre_test_split5)\n",
    "    \n",
    "print(precision_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_precision = statistics.mean(precision_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "precision_sd = statistics.stdev(precision_values)\n",
    "\n",
    "print(\"Mean precision:\", mean_precision)\n",
    "print(\"precision Standard Deviation:\", precision_sd)\n",
    "\n",
    "# Print mean specificity with standard deviation\n",
    "print(\"Overall precision: %.2f  %.2f%%\" % (mean_precision, precision_sd))\n",
    "\n",
    "f1_values = []\n",
    "\n",
    "f1_values.append(f1_test_split1)\n",
    "f1_values.append(f1_test_split2)\n",
    "f1_values.append(f1_test_split3)\n",
    "f1_values.append(f1_test_split4)\n",
    "f1_values.append(f1_test_split5)\n",
    "    \n",
    "print(f1_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_f1 = statistics.mean(f1_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "f1_sd = statistics.stdev(f1_values)\n",
    "\n",
    "print(\"Mean f1:\", mean_f1)\n",
    "print(\"f1 Standard Deviation:\", f1_sd)\n",
    "\n",
    "# Print mean specificity with standard deviation\n",
    "print(\"Overall f1: %.2f  %.2f%%\" % (mean_f1, f1_sd))\n",
    "\n",
    "auc_values = []\n",
    "\n",
    "auc_values.append(auc_test_split1)\n",
    "auc_values.append(auc_test_split2)\n",
    "auc_values.append(auc_test_split3)\n",
    "auc_values.append(auc_test_split4)\n",
    "auc_values.append(auc_test_split5)\n",
    "    \n",
    "print(auc_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_auc = statistics.mean(auc_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "auc_sd = statistics.stdev(auc_values)\n",
    "\n",
    "print(\"Mean auc:\", mean_auc)\n",
    "print(\"auc Standard Deviation:\", auc_sd)\n",
    "\n",
    "# Print mean auc with standard deviation\n",
    "print(\"Overall auc: %.2f  %.2f%%\" % (mean_auc, auc_sd))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d25aa45c",
   "metadata": {},
   "source": [
    "parameter4 split4 ( split2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d806482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split4'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d26aa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search svm model\n",
    "\n",
    "# define model\n",
    "model = SVC()\n",
    "\n",
    "# define parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, param_grid, refit = True)\n",
    "\n",
    "# execute search\n",
    "result = search.fit(x_val, y_val)\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76038019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the individual models\n",
    "model = SVC(C=10, gamma=0.01, kernel='sigmoid')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param4/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c83a5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split4 = sensitivity(cm_test)\n",
    "spec_test_split4 = specificity(cm_test)\n",
    "acc_test_split4 = accuracy(cm_test)\n",
    "pre_test_split4 = precision(cm_test)\n",
    "f1_test_split4 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split4 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split4)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split4))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf0ff771",
   "metadata": {},
   "source": [
    "split1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4008ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split1'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param4/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb08e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split1 = sensitivity(cm_test)\n",
    "spec_test_split1 = specificity(cm_test)\n",
    "acc_test_split1 = accuracy(cm_test)\n",
    "pre_test_split1 = precision(cm_test)\n",
    "f1_test_split1 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split1 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split1)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split1))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef63b6ee",
   "metadata": {},
   "source": [
    "split2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dbd107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split2'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param4/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6239d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split2 = sensitivity(cm_test)\n",
    "spec_test_split2 = specificity(cm_test)\n",
    "acc_test_split2 = accuracy(cm_test)\n",
    "pre_test_split2 = precision(cm_test)\n",
    "f1_test_split2 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split2 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split2)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split2))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fdcaaec",
   "metadata": {},
   "source": [
    "split3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d8ae93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split3'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param4/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec4efbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split3 = sensitivity(cm_test)\n",
    "spec_test_split3 = specificity(cm_test)\n",
    "acc_test_split3 = accuracy(cm_test)\n",
    "pre_test_split3 = precision(cm_test)\n",
    "f1_test_split3 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split3 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split3)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split3))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "07285a29",
   "metadata": {},
   "source": [
    "split5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc90a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split5'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param4/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114c8b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split5 = sensitivity(cm_test)\n",
    "spec_test_split5 = specificity(cm_test)\n",
    "acc_test_split5 = accuracy(cm_test)\n",
    "pre_test_split5 = precision(cm_test)\n",
    "f1_test_split5 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split5 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split5)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split5))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dbf624e3",
   "metadata": {},
   "source": [
    "overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b2abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_values = []\n",
    "\n",
    "sensitivity_values.append(sen_test_split1)\n",
    "sensitivity_values.append(sen_test_split2)\n",
    "sensitivity_values.append(sen_test_split3)\n",
    "sensitivity_values.append(sen_test_split4)\n",
    "sensitivity_values.append(sen_test_split5)\n",
    "\n",
    "print(sensitivity_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_sensitivity = statistics.mean(sensitivity_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "sensitivity_sd = statistics.stdev(sensitivity_values)\n",
    "\n",
    "print(\"Mean Sensitivity:\", mean_sensitivity)\n",
    "print(\"Sensitivity Standard Deviation:\", sensitivity_sd)\n",
    "\n",
    "# Print mean sensitivity with standard deviation\n",
    "print(\"Overall Sensitivity: %.2f  %.2f%%\" % (mean_sensitivity, sensitivity_sd))\n",
    "\n",
    "specificity_values = []\n",
    "\n",
    "specificity_values.append(spec_test_split1)\n",
    "specificity_values.append(spec_test_split2)\n",
    "specificity_values.append(spec_test_split3)\n",
    "specificity_values.append(spec_test_split4)\n",
    "specificity_values.append(spec_test_split5)\n",
    "    \n",
    "print(specificity_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_specificity = statistics.mean(specificity_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "specificity_sd = statistics.stdev(specificity_values)\n",
    "\n",
    "print(\"Mean Specificity:\", mean_specificity)\n",
    "print(\"Specificity Standard Deviation:\", specificity_sd)\n",
    "\n",
    "# Print mean specificity with standard deviation\n",
    "print(\"Overall Specificity: %.2f  %.2f%%\" % (mean_specificity, specificity_sd))\n",
    "\n",
    "accuracy_values = []\n",
    "\n",
    "accuracy_values.append(acc_test_split1)\n",
    "accuracy_values.append(acc_test_split2)\n",
    "accuracy_values.append(acc_test_split3)\n",
    "accuracy_values.append(acc_test_split4)\n",
    "accuracy_values.append(acc_test_split5)\n",
    "    \n",
    "print(accuracy_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_accuracy = statistics.mean(accuracy_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "accuracy_sd = statistics.stdev(accuracy_values)\n",
    "\n",
    "print(\"Mean accuracy:\", mean_accuracy)\n",
    "print(\"accuracy Standard Deviation:\", accuracy_sd)\n",
    "\n",
    "# Print mean accuracy with standard deviation\n",
    "print(\"Overall accuracy: %.2f  %.2f%%\" % (mean_accuracy, accuracy_sd))\n",
    "\n",
    "precision_values = []\n",
    "\n",
    "precision_values.append(pre_test_split1)\n",
    "precision_values.append(pre_test_split2)\n",
    "precision_values.append(pre_test_split3)\n",
    "precision_values.append(pre_test_split4)\n",
    "precision_values.append(pre_test_split5)\n",
    "    \n",
    "print(precision_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_precision = statistics.mean(precision_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "precision_sd = statistics.stdev(precision_values)\n",
    "\n",
    "print(\"Mean precision:\", mean_precision)\n",
    "print(\"precision Standard Deviation:\", precision_sd)\n",
    "\n",
    "# Print mean specificity with standard deviation\n",
    "print(\"Overall precision: %.2f  %.2f%%\" % (mean_precision, precision_sd))\n",
    "\n",
    "f1_values = []\n",
    "\n",
    "f1_values.append(f1_test_split1)\n",
    "f1_values.append(f1_test_split2)\n",
    "f1_values.append(f1_test_split3)\n",
    "f1_values.append(f1_test_split4)\n",
    "f1_values.append(f1_test_split5)\n",
    "    \n",
    "print(f1_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_f1 = statistics.mean(f1_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "f1_sd = statistics.stdev(f1_values)\n",
    "\n",
    "print(\"Mean f1:\", mean_f1)\n",
    "print(\"f1 Standard Deviation:\", f1_sd)\n",
    "\n",
    "# Print mean specificity with standard deviation\n",
    "print(\"Overall f1: %.2f  %.2f%%\" % (mean_f1, f1_sd))\n",
    "\n",
    "auc_values = []\n",
    "\n",
    "auc_values.append(auc_test_split1)\n",
    "auc_values.append(auc_test_split2)\n",
    "auc_values.append(auc_test_split3)\n",
    "auc_values.append(auc_test_split4)\n",
    "auc_values.append(auc_test_split5)\n",
    "    \n",
    "print(auc_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_auc = statistics.mean(auc_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "auc_sd = statistics.stdev(auc_values)\n",
    "\n",
    "print(\"Mean auc:\", mean_auc)\n",
    "print(\"auc Standard Deviation:\", auc_sd)\n",
    "\n",
    "# Print mean auc with standard deviation\n",
    "print(\"Overall auc: %.2f  %.2f%%\" % (mean_auc, auc_sd))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04738889",
   "metadata": {},
   "source": [
    "parameter5 split5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f73b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split5'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d3186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search svm model\n",
    "\n",
    "# define model\n",
    "model = SVC()\n",
    "\n",
    "# define parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, param_grid, refit = True)\n",
    "\n",
    "# execute search\n",
    "result = search.fit(x_val, y_val)\n",
    "\n",
    "# summarize result\n",
    "print('Best Score: %s' % result.best_score_)\n",
    "print('Best Hyperparameters: %s' % result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab39974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the individual models\n",
    "model = SVC(C=0.1, gamma=1, kernel='linear')\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param5/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a29e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split5 = sensitivity(cm_test)\n",
    "spec_test_split5 = specificity(cm_test)\n",
    "acc_test_split5 = accuracy(cm_test)\n",
    "pre_test_split5 = precision(cm_test)\n",
    "f1_test_split5 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split5 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split5)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split5))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f70fcdbf",
   "metadata": {},
   "source": [
    "split1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a41767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split1'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param5/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e24c556",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split1 = sensitivity(cm_test)\n",
    "spec_test_split1 = specificity(cm_test)\n",
    "acc_test_split1 = accuracy(cm_test)\n",
    "pre_test_split1 = precision(cm_test)\n",
    "f1_test_split1 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split1 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split1)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split1))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9cd87c5",
   "metadata": {},
   "source": [
    "split2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00ba437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split2'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param5/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b73df7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split2 = sensitivity(cm_test)\n",
    "spec_test_split2 = specificity(cm_test)\n",
    "acc_test_split2 = accuracy(cm_test)\n",
    "pre_test_split2 = precision(cm_test)\n",
    "f1_test_split2 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split2 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split2)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split2))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3313d88f",
   "metadata": {},
   "source": [
    "split3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b3ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split3'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param5/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e085dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split3 = sensitivity(cm_test)\n",
    "spec_test_split3 = specificity(cm_test)\n",
    "acc_test_split3 = accuracy(cm_test)\n",
    "pre_test_split3 = precision(cm_test)\n",
    "f1_test_split3 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split3 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split3)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split3))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f38ca11",
   "metadata": {},
   "source": [
    "split4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450fdfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting split and path\n",
    "split = 'split4'\n",
    "path = \"../Anny_oversampling/DATA\"\n",
    "train_path = \"{}/{}/train/oversampled_train_{}.csv\".format(path,split,split)\n",
    "test_path =  \"{}/test.csv\".format(path)\n",
    "val_path = \"{}/{}/val/val_{}.csv\".format(path,split,split)\n",
    "\n",
    "# Load the training set\n",
    "train_data = pd.read_csv(train_path)\n",
    "print(train_data.shape)\n",
    "x_train = train_data[train_data.columns[2:]]\n",
    "print(x_train.shape)\n",
    "y_train = train_data[train_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_train = np.array(le.fit_transform(y_train))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the testing set\n",
    "test_data = pd.read_csv(test_path)\n",
    "print(test_data.shape)\n",
    "x_test = test_data[test_data.columns[3:]]\n",
    "print(x_test.shape)\n",
    "y_test = test_data[test_data.columns[2]]\n",
    "le = LabelEncoder()\n",
    "y_test = np.array(le.fit_transform(y_test))\n",
    "print(le.classes_)\n",
    "\n",
    "# Load the validation set\n",
    "val_data = pd.read_csv(val_path)\n",
    "print(val_data.shape)\n",
    "x_val = val_data[val_data.columns[2:]]\n",
    "print(x_val.shape)\n",
    "y_val = val_data[val_data.columns[1]]\n",
    "le = LabelEncoder()\n",
    "y_val = np.array(le.fit_transform(y_val))\n",
    "print(le.classes_)\n",
    "\n",
    "# check balance in this split\n",
    "print(split)\n",
    "print(\"train positive:    \" + str(sum(y_train)))\n",
    "print(\"validate positive: \" + str(sum(y_val)))\n",
    "\n",
    "x_train = x_train.to_numpy()\n",
    "x_test = x_test.to_numpy()\n",
    "x_val = x_val.to_numpy()\n",
    "\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)\n",
    "x_val = sc.fit_transform(x_val)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "model_path = \"../SVM/models/param5/svm_model_{}.pkl\".format(split)\n",
    "\n",
    "# Save the trained model to disk\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# Load the saved model from disk\n",
    "model = joblib.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7a5bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split)\n",
    "############## validate set ################\n",
    "print(\"############## validate set ################\")\n",
    "y_pred_val = model.predict(x_val)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_val = confusion_matrix(y_val, y_pred_val)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_val,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_val = sensitivity(cm_val)\n",
    "spec_val = specificity(cm_val)\n",
    "acc_val = accuracy(cm_val)\n",
    "pre_val = precision(cm_val)\n",
    "f1_val = f1(cm_val)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_val = cm_val.astype('float') / cm_val.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_val, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_val.shape[1]),\n",
    "       yticks=np.arange(cm_norm_val.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Validate set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_val.max() / 2.\n",
    "for i in range(cm_norm_val.shape[0]):\n",
    "    for j in range(cm_norm_val.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_val[i,j], cm_norm_val[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_val[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################# test set ##################\n",
    "print(\"################# test set ##################\")\n",
    "y_pred_test = model.predict(x_test)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm_test = confusion_matrix(y_test, y_pred_test)\n",
    "print('Confusion Matrix')\n",
    "print('-'*16)\n",
    "print(cm_test,'\\n')\n",
    "print('-'*16)\n",
    "\n",
    "# Calculate score\n",
    "sen_test_split4 = sensitivity(cm_test)\n",
    "spec_test_split4 = specificity(cm_test)\n",
    "acc_test_split4 = accuracy(cm_test)\n",
    "pre_test_split4 = precision(cm_test)\n",
    "f1_test_split4 = f1(cm_test)\n",
    "\n",
    "# plot confusion matrix\n",
    "class_names = ['benign','malignant']\n",
    "# Normalize confusion matrix to percentage\n",
    "cm_norm_test = cm_test.astype('float') / cm_test.sum(axis=1)[:, np.newaxis]\n",
    "# Create plot\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(cm_norm_test, interpolation='nearest', cmap=\"rocket_r\")\n",
    "ax.grid(False)\n",
    "# Add labels\n",
    "ax.set(xticks=np.arange(cm_norm_test.shape[1]),\n",
    "       yticks=np.arange(cm_norm_test.shape[0]),\n",
    "       xticklabels=class_names, yticklabels=class_names)\n",
    "ax.set_title(\"Test set\", fontsize=16)\n",
    "ax.set_ylabel('Actual', fontsize=16)\n",
    "ax.set_xlabel('Predicted', fontsize=16)\n",
    "# Add percentage and count values inside plot\n",
    "thresh = cm_norm_test.max() / 2.\n",
    "for i in range(cm_norm_test.shape[0]):\n",
    "    for j in range(cm_norm_test.shape[1]):\n",
    "        ax.text(j, i, '''{}\\n({:.2f}%)'''.format(cm_test[i,j], cm_norm_test[i, j]*100),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                color=\"white\" if cm_norm_test[i, j] > thresh else \"black\")\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "################## plot ROC curve ########################\n",
    "fpr1, tpr1, thr1 = roc_curve(y_val, y_pred_val)\n",
    "auc_val = roc_auc_score(y_val, y_pred_val)\n",
    "fpr2, tpr2, thr2 = roc_curve(y_test, y_pred_test)\n",
    "auc_test_split4 = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"---------------------------------------\")\n",
    "print(\"AUC validate: %.4f\" % auc_val)\n",
    "print(\"AUC test: %.4f\" % auc_test_split4)\n",
    "\n",
    "# plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc),color='red')\n",
    "plt.plot(fpr1,tpr1,label=\"ROC valid, auc=\"+str(\"%.4f\" % auc_val))\n",
    "plt.plot(fpr2,tpr2,label=\"ROC test, auc=\"+str(\"%.4f\" % auc_test_split4))\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"Chance\", alpha=0.8)\n",
    "plt.legend(loc=4)\n",
    "plt.show()\n",
    "##########################################################"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a0969b7",
   "metadata": {},
   "source": [
    "overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472ac61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_values = []\n",
    "\n",
    "sensitivity_values.append(sen_test_split1)\n",
    "sensitivity_values.append(sen_test_split2)\n",
    "sensitivity_values.append(sen_test_split3)\n",
    "sensitivity_values.append(sen_test_split4)\n",
    "sensitivity_values.append(sen_test_split5)\n",
    "\n",
    "print(sensitivity_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_sensitivity = statistics.mean(sensitivity_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "sensitivity_sd = statistics.stdev(sensitivity_values)\n",
    "\n",
    "print(\"Mean Sensitivity:\", mean_sensitivity)\n",
    "print(\"Sensitivity Standard Deviation:\", sensitivity_sd)\n",
    "\n",
    "# Print mean sensitivity with standard deviation\n",
    "print(\"Overall Sensitivity: %.2f  %.2f%%\" % (mean_sensitivity, sensitivity_sd))\n",
    "\n",
    "specificity_values = []\n",
    "\n",
    "specificity_values.append(spec_test_split1)\n",
    "specificity_values.append(spec_test_split2)\n",
    "specificity_values.append(spec_test_split3)\n",
    "specificity_values.append(spec_test_split4)\n",
    "specificity_values.append(spec_test_split5)\n",
    "    \n",
    "print(specificity_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_specificity = statistics.mean(specificity_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "specificity_sd = statistics.stdev(specificity_values)\n",
    "\n",
    "print(\"Mean Specificity:\", mean_specificity)\n",
    "print(\"Specificity Standard Deviation:\", specificity_sd)\n",
    "\n",
    "# Print mean specificity with standard deviation\n",
    "print(\"Overall Specificity: %.2f  %.2f%%\" % (mean_specificity, specificity_sd))\n",
    "\n",
    "accuracy_values = []\n",
    "\n",
    "accuracy_values.append(acc_test_split1)\n",
    "accuracy_values.append(acc_test_split2)\n",
    "accuracy_values.append(acc_test_split3)\n",
    "accuracy_values.append(acc_test_split4)\n",
    "accuracy_values.append(acc_test_split5)\n",
    "    \n",
    "print(accuracy_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_accuracy = statistics.mean(accuracy_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "accuracy_sd = statistics.stdev(accuracy_values)\n",
    "\n",
    "print(\"Mean accuracy:\", mean_accuracy)\n",
    "print(\"accuracy Standard Deviation:\", accuracy_sd)\n",
    "\n",
    "# Print mean accuracy with standard deviation\n",
    "print(\"Overall accuracy: %.2f  %.2f%%\" % (mean_accuracy, accuracy_sd))\n",
    "\n",
    "precision_values = []\n",
    "\n",
    "precision_values.append(pre_test_split1)\n",
    "precision_values.append(pre_test_split2)\n",
    "precision_values.append(pre_test_split3)\n",
    "precision_values.append(pre_test_split4)\n",
    "precision_values.append(pre_test_split5)\n",
    "    \n",
    "print(precision_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_precision = statistics.mean(precision_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "precision_sd = statistics.stdev(precision_values)\n",
    "\n",
    "print(\"Mean precision:\", mean_precision)\n",
    "print(\"precision Standard Deviation:\", precision_sd)\n",
    "\n",
    "# Print mean specificity with standard deviation\n",
    "print(\"Overall precision: %.2f  %.2f%%\" % (mean_precision, precision_sd))\n",
    "\n",
    "f1_values = []\n",
    "\n",
    "f1_values.append(f1_test_split1)\n",
    "f1_values.append(f1_test_split2)\n",
    "f1_values.append(f1_test_split3)\n",
    "f1_values.append(f1_test_split4)\n",
    "f1_values.append(f1_test_split5)\n",
    "    \n",
    "print(f1_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_f1 = statistics.mean(f1_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "f1_sd = statistics.stdev(f1_values)\n",
    "\n",
    "print(\"Mean f1:\", mean_f1)\n",
    "print(\"f1 Standard Deviation:\", f1_sd)\n",
    "\n",
    "# Print mean specificity with standard deviation\n",
    "print(\"Overall f1: %.2f  %.2f%%\" % (mean_f1, f1_sd))\n",
    "\n",
    "auc_values = []\n",
    "\n",
    "auc_values.append(auc_test_split1)\n",
    "auc_values.append(auc_test_split2)\n",
    "auc_values.append(auc_test_split3)\n",
    "auc_values.append(auc_test_split4)\n",
    "auc_values.append(auc_test_split5)\n",
    "    \n",
    "print(auc_values)\n",
    "\n",
    "# calculating the mean of sample set\n",
    "mean_auc = statistics.mean(auc_values)\n",
    "# Calculate standard deviation of sensitivity\n",
    "auc_sd = statistics.stdev(auc_values)\n",
    "\n",
    "print(\"Mean auc:\", mean_auc)\n",
    "print(\"auc Standard Deviation:\", auc_sd)\n",
    "\n",
    "# Print mean auc with standard deviation\n",
    "print(\"Overall auc: %.2f  %.2f%%\" % (mean_auc, auc_sd))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "23bf0724a01b6ea9814e66f76182ea78c0ee849a72ca257c0e116bf83bb4960a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
