{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d86101b2-49ff-4513-9562-80a783864de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "670160ac-b454-4d85-82fd-dbf9da7526a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(split):\n",
    "    # setting split and path\n",
    "    path = \"../kitt/DATA_progress3/\"\n",
    "    train_path = \"{}/{}/train/train_oversampling.csv\".format(path,split)\n",
    "    test_path =  \"{}/test.csv\".format(path)\n",
    "    valid_path = \"{}/{}/val/val.csv\".format(path,split)\n",
    "\n",
    "    print(train_path)\n",
    "    # Load the train set\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    print(train_data.shape)\n",
    "    x_train = train_data[train_data.columns[2:]]\n",
    "    print(x_train.shape)\n",
    "    y_train = train_data[train_data.columns[1]]\n",
    "    le = LabelEncoder()\n",
    "    y_train = np.array(le.fit_transform(y_train))\n",
    "    print(le.classes_)\n",
    "    print(test_path)\n",
    "    # Load the test set\n",
    "    test_data = pd.read_csv(test_path)\n",
    "    print(test_data.shape)\n",
    "    x_test = test_data[test_data.columns[2:]]\n",
    "    print(x_test.shape)\n",
    "    y_test = test_data[test_data.columns[1]]\n",
    "    le = LabelEncoder()\n",
    "    y_test = np.array(le.fit_transform(y_test))\n",
    "    print(le.classes_)\n",
    "\n",
    "    print(valid_path)\n",
    "    # Load the validation set\n",
    "    val_data = pd.read_csv(valid_path)\n",
    "    print(val_data.shape)\n",
    "    x_val = val_data[val_data.columns[2:]]\n",
    "    print(x_val.shape)\n",
    "    y_val = val_data[val_data.columns[1]]\n",
    "    le = LabelEncoder()\n",
    "    y_val = np.array(le.fit_transform(y_val))\n",
    "    print(le.classes_)\n",
    "\n",
    "    # StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    x_train = x_train.to_numpy()\n",
    "    x_test = x_test.to_numpy()\n",
    "    x_val = x_val.to_numpy()\n",
    "    x_train = sc.fit_transform(x_train)\n",
    "    x_test = sc.transform(x_test)\n",
    "    x_val = sc.transform(x_val)\n",
    "    \n",
    "    return x_train,y_train,x_test,y_test,x_val,y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8b521b06-49f9-4687-95b7-54bcbf5facfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../kitt/DATA_progress3//split1/train/train_oversampling.csv\n",
      "(504, 18)\n",
      "(504, 16)\n",
      "['B' 'M']\n",
      "../kitt/DATA_progress3//test.csv\n",
      "(114, 18)\n",
      "(114, 16)\n",
      "['B' 'M']\n",
      "../kitt/DATA_progress3//split1/val/val.csv\n",
      "(91, 18)\n",
      "(91, 16)\n",
      "['B' 'M']\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train,x_test,y_test,x_val,y_val = setup(\"split1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6ecc601f-a32c-4e8f-ae74-e723397c98e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversampling(split):\n",
    "    # setting split and path\n",
    "    path = \"../kitt/DATA_progress3/\"\n",
    "    train_path = \"{}/{}/train/train.csv\".format(path,split)\n",
    "    train_data = pd.read_csv(train_path)\n",
    "    # create data frame\n",
    "    B_dataframe = train_data[train_data[\"diagnosis\"]==\"B\"]\n",
    "    M_dataframe = train_data[train_data[\"diagnosis\"]==\"M\"]\n",
    "    # count data\n",
    "    B_data = len(B_dataframe)\n",
    "    print(\"B_data: \" + str(B_data))\n",
    "    M_data = len(M_dataframe)\n",
    "    print(\"M_data: \" + str(M_data))\n",
    "    # double\n",
    "    M_dataframe = pd.concat([M_dataframe]*2, ignore_index=True)\n",
    "    M_data_double = len(M_dataframe)\n",
    "    print(\"M_data_double: \" + str(M_data_double))\n",
    "    # over data\n",
    "    over_data = M_dataframe.sample(B_data - M_data_double)\n",
    "    print(\"M_data_double: \" + str(len(over_data)))\n",
    "    # oversampling\n",
    "    train_oversampling = pd.concat([M_dataframe, over_data, B_dataframe])\n",
    "    return train_oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e639c147-d67e-455e-8af4-0adcf5055627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_data: 252\n",
      "M_data: 112\n",
      "M_data_double: 224\n",
      "M_data_double: 28\n"
     ]
    }
   ],
   "source": [
    "split = \"split1\"\n",
    "train_oversampling1 = oversampling(split)\n",
    "train_oversampling1.to_csv(\"../kitt/DATA_progress3/{}/train/train_oversampling.csv\".format(split),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ad6580cf-27f7-4b61-ae29-33bd742a1af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_data: 252\n",
      "M_data: 112\n",
      "M_data_double: 224\n",
      "M_data_double: 28\n"
     ]
    }
   ],
   "source": [
    "split = \"split2\"\n",
    "train_oversampling1 = oversampling(split)\n",
    "train_oversampling1.to_csv(\"../kitt/DATA_progress3/{}/train/train_oversampling.csv\".format(split),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "37f7004c-b236-4186-a7a9-41eb51d0d282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_data: 252\n",
      "M_data: 112\n",
      "M_data_double: 224\n",
      "M_data_double: 28\n"
     ]
    }
   ],
   "source": [
    "split = \"split3\"\n",
    "train_oversampling1 = oversampling(split)\n",
    "train_oversampling1.to_csv(\"../kitt/DATA_progress3/{}/train/train_oversampling.csv\".format(split),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "88e32dfc-e572-4ebd-a863-bf61150c2a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_data: 252\n",
      "M_data: 112\n",
      "M_data_double: 224\n",
      "M_data_double: 28\n"
     ]
    }
   ],
   "source": [
    "split = \"split4\"\n",
    "train_oversampling1 = oversampling(split)\n",
    "train_oversampling1.to_csv(\"../kitt/DATA_progress3/{}/train/train_oversampling.csv\".format(split),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b4bde655-cffb-45e7-b7e3-5dac715d61e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_data: 252\n",
      "M_data: 112\n",
      "M_data_double: 224\n",
      "M_data_double: 28\n"
     ]
    }
   ],
   "source": [
    "split = \"split5\"\n",
    "train_oversampling1 = oversampling(split)\n",
    "train_oversampling1.to_csv(\"../kitt/DATA_progress3/{}/train/train_oversampling.csv\".format(split),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d597a9d-c273-4613-a9e8-d502a6b8af32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
